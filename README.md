# Multiclass Classification: Understanding Neural Networks from Scratch

## Introduction

Undertook: In Jan-Feb 2023, Uploading it to Github now.

Welcome to the Neural Network Implementation project! This project was undertaken to get a deep and fundamental understanding of neural networks by implementing them from scratch, without relying on any deep learning frameworks. By delving into the intricacies of neural network architectures and optimization algorithms, a comprehensive understanding of how these models work and how they can be optimized for better performance.

## Purpose

The primary purpose of this project was to gain a hands-on learning experience for understanding neural networks at a fundamental level. By building neural networks from scratch, I got insight into the inner workings of these models, including the role of activation functions, parameter initialization, forward and backward propagation, and optimization techniques. This approach fostered a deeper understanding of neural network concepts and enabled me to develop robust and efficient models tailored to specific tasks.

## Dataset
The dataset used for training and evaluation is the Fashion MNIST dataset. This dataset consists of 60,000 training images and 10,000 test images, each of size 28x28 pixels. The images belong to 10 different categories of fashion items, including T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, and Ankle boot.

## Implementation Details
The neural network architecture used for this project has the following layers:
- Input layer: 784 units (28x28 pixels)
- Hidden layers: Two hidden layers with 1000 units each
- Output layer: 10 Softmax units (corresponding to the 10 fashion categories)
- He Initialization

## Outputs
![Ouptput1](./Ouputs/Training_Output.png)
![Ouptput1](./Ouputs/Outpu1.png)
![Ouptput2](./Ouputs/Outpu2.png)
![Ouptput3](./Ouputs/Outpu3.png)
